Быстрая сортировка, известная также как сортировка Хоара, является одним из наиболее известных и широко используемых алгоритмов сортировки. Её эффективность и простота реализации делают её популярным выбором для многих практических 
приложений.

#####################
Основная идея алгоритма

Быстрая сортировка использует стратегию "разделяй и властвуй", чтобы эффективно упорядочить данные. Основные шаги алгоритма следующие:

1. Выбор опорного элемента: Из массива выбирается один элемент, называемый "опорным". Этот выбор может быть случайным, фиксированным (например, первый или последний элемент) или более сложным (медиана трёх и т.д.).

2. Разбиение: Массив перераспределяется таким образом, что элементы меньше опорного перемещаются перед ним, а большие или равные — после. Этот процесс называется "разбиением".

3. Рекурсивная сортировка: Алгоритм рекурсивно применяется к двум подмассивам: элементам до и после опорного.


#####################
Процесс разбиения

Наиболее критичной частью быстрой сортировки является процесс разбиения. В классическом варианте разбиения (метод Хоара):

1) Опорный элемент выбирается и фиксируется (например, последний элемент массива).
2) Используются два указателя, начинающихся с начала и конца массива.
3) Эти указатели двигаются навстречу друг другу, и когда находится элемент больше опорного слева от опорного и меньше опорного справа, они обмениваются местами.
Процесс продолжается, пока указатели не пересекутся.

На самом деле опорный элемент можно выбирать самым разным образом, либо брать случайный элемент, либо брать первый / последний элемент участка, либо выбирать его каким-то "умным образом". Выбор опроного элемента является очень важным для
итоговой сложности алгоритма сортировки, однако оптимальный опорный элемент всегда рандомный в разных последовательностях В ранних реализациях опорным элементом выбирался первый элемент, что снижало производительность н аотсортированных
массивах. Для улучшения эффективности может выбираться средний, случайный элемент, или (для большинства массивов) медиана первого, среднего и последнего элементов. Медиана всей последовательности является оптимальным опорным элементом, не
её вычисление слишком трудоёмко для использование в сортировки.

Выбор опорного элемента по медиане трёх для разбиения Ломуто:
int indexMid =  left + right / 2;
if (arr[indexMid] < arr[left])
	std::swap(arr[indexMid], arr[left]);
if (arr[right] < arr[left])
	std::swap(arr[left], arr[right]);
if (arr[right] < arr[indexMid])
	std::swap(arr[right], arr[indexMid]);
int pivot = A[indexMid];

Однако, поскольку оптимальным может оказаться любой элемент с равной вероятностью, гораздо разумнее выбирать случайный элемент, это гарантирует что никто злонамеренно не сможет соорудить массив, который этот алгоритм введёт в очень долгий
цикл с переполнением стека. Неудачей считается число итераций (полного перебора всех элементов массива с целью сравнения и перестановки) более чем 200.


#####################
Пример:

#include <iostream>
#include <vector>

void quickSort(std::vector<int>& arr, int left, int right) {
    if (left >= right) return;

    int pivot = arr[right];  // Опорный элемент (здесь он является последним)
    int i = left;            // Начало массива
    int j = right - 1;       // Конец массива, исключая опорный элемент

    while (i <= j) {
        while (i <= j && arr[i] < pivot) i++;
        while (i <= j && arr[j] > pivot) j--;
        if (i <= j) {
            std::swap(arr[i], arr[j]);
            i++;
            j--;
        }
    }
    std::swap(arr[i], arr[right]);  // Меняем местами опорный элемент с элементом на позиции i

    quickSort(arr, left, i - 1);    // Рекурсивная сортировка левой части
    quickSort(arr, i + 1, right);   // Рекурсивная сортировка правой части
}

int main() {
    std::vector<int> data = {9, 7, 5, 11, 12, 2, 14, 3, 10, 6};
    quickSort(data, 0, data.size() - 1);

    for (int num : data) {
        std::cout << num << " ";
    }
    std::cout << std::endl;
    return 0;
}



#####################
Вторая реализация(чуть более быстрее)
void QuickSortRecursion(int* arr, int left, int right) {
    if (left >= right) return;

    int pivot = arr[(left + right) / 2];  // опорный элемент
    int i = left;
    int j = right;

    while (i <= j) {
        while (arr[i] < pivot) i++;
        while (arr[j] > pivot) j--;

        if (i <= j) {
            std::swap(arr[i], arr[j]);
            i++;
            j--;
        }
    }

    // Рекурсивно вызываем для левой и правой части
    if (left < j) QuickSortRecursion(arr, left, j);
    if (i < right) QuickSortRecursion(arr, i, right);

    /*
    * Реализация если опорный элемент будет последним элементом массива.
    * Это ни на что не влияет, оптимальный опорный элемент всегда рандомный в разных последовательностях
    if (left >= right) return;

    int pivot = arr[right];
    int i = left;
    int j = right - 1;

    while (i <= j) {
        while (i <= j && arr[i] <= pivot) ++i;
        while (i <= j && arr[j] > pivot) --j;

        if (i <= j) {
            std::swap(arr[i], arr[j]);
            ++i; --j;
        }
    }

    std::swap(arr[i], arr[right]);
    QuickSortRecursion(arr, left, i - 1);
    QuickSortRecursion(arr, i + 1, right);
    */
}



#####################
Сложность алгоритма

Быстрая сортировка часто предпочтительнее других алгоритмов из-за её эффективности в среднем и лучшем случае и хорошей адаптивности к различным наборам данных.

Лучший случай: O(n log n), когда разбиения делят массив на равные части.
Средний случай: O(n log n), что делает его очень эффективным для большинства наборов данных.
Худший случай: O(n^2), который возникает, когда каждое разбиение делит массив так, что одна часть содержит все элементы, кроме одного. В частности, это происходит, если массив изначально отсортирован.

Применение: Очень эффективен для больших массивов, но может быть нестабильным.

Ясно что операция разделения массива на две части относительно опорного элемента занимает O(n). Поскольку все операции разделения, проделываемые на одной глубине рекурсии, обрабатывают разные части исходного массива, размер которого постоянен,
суммарно на каждом уровне рекурсии потребуется также O(n) операций. Следовательно, общая сложность алгоритма определяется лишь кол-вом разделений, т.е. глубиной рекурсии. Глубина рекурсии в свою очередь зависит от сочетания входных данных и 
способа определения опорного элемента.

Лучший случай: В наиболее сбалансированном варианте при каждой операции разделения массив делится на две одинаковые части, следовательно, максимальная глубина рекурсии, при которой размеры обрабатываемых подмассивов достигнут 1, составит 
log_2 n. В результате количество сравнений было бы равно значению рекурсивного выражения: C_n = 2 *  C_n/2 + n, что даёт общую сложность алгоритма O(n*log_2 n).

Средний случай: среднюю сложность при случайном распределении входных данных можно оценить лишь вероятностно. Прежде всего необходимо заметить, что в действительности необяхательно, чтобы опорный элемент всякий раз делил массив на две 
одинаковые части. Например, если на каждом этапе будет происходить разделение на массивы длинной 75% и 25% от исходного, глубина рекурсии будет равна log_4/3 n, а это по-прежнему даёт сложность O(n log n). Будем считать удачным разделением такое,
при котором опорный элемент окажется среди центральных 50% элементов разделяемой части массива, тогда вероятность удачи при случайном распределении элементов составит 0,5. Поскольку каждый выделенный подмассив также будет иметь случайное
распределение , все эти рассуждения применимы к любому этапу сортировки. Получается удачное разделение даёт глубину рекурсии не более log_4/3 n. Поскольку вероятность удачи равна 0,5, для получения k удачных разделений в среднем потребуется 
2 * k рекурсивных вызовов. Применяя эти соображения можно заключить, что средняя глубина рекурсии не превысит 2 * log_4/3 n, что равно O(log n), а поскольку на каждом уровне рекурсии по-прежнему выполняется не более O(n) операций, средняя 
сложность составит O(n log n).

Худший случай: В самом несбалансированном варианте каждое разделение даёт два подмассива размерами 1 и n - 1, т.е. при каждом рекурсивном вызове больший массив будет на 1 короче , чем в предыдущий раз. Такое может произойти, если в качестве 
опорного на каждом этапе будет выбран элемент либо наименьший, либо наибольший из всех обрабатываемых. При простейшем выборе опорного элемента (первого или последнего) такой эффект даст уже отсортированный(прямой или в обратном порядке)
массив. "Массив худшего случая" м.б. подобран под любой опорный элемент. В таком случае общее время работы составит O(n^2), и потребуется n - 1 операций разделения. Но это ещё не самое плохое, хуже то, что в таком случае глубина рекурсий достигнет
n, что будет означать n-кратное сохранение адреса возврата и локальных переменных процедуры разделения массива.  Для больших значений n это может превести к переполнению стека.


#####################
Достоинства:
- Один из самых быстродействующих (на практике) из алгоритмов внутренней сортировки общего назначения.
- Алгоритм очень короткий
- С модификациями ребует лишь O(log n) дополнительной памяти в виде стека, в худшем случае O(n) стека.
- Хорошо сочитается с механизмами кэширования и виртуальной памяти.
- Допускает естественное распараллеливание.
- Допускает эффективную модификацию для сортировки по нескольким ключам (в частности - алгоритм Седжвика для сортировки строк).

Недостатки:
- Сильно деградирует по скорости до O(n^2) в худшем или близком к нему случае при неудачных входных данных.
- Прямая реализация в виде функции с двумя рекурсивными вызовами может привести к ошибке переподнения стека.
- Неустойчив


#####################
Улучшения и модификации

Улучшения алгоритма направлены на устранения или смягчения вышеупомянутых недостатков, в следствии чего все их можно разделить на три группы: придание устойчивости, устарнение деградации производительности специальным выбором опорного
элемента и защита от переполнения стека.

Проблема неустойчивости решается путём расширения ключа исходным индексом элемента в массиве. В случае равенства основных ключей сравнение производится по индексу, исключая, т.о.  возможность изменения взаимного положения равных элементов.
Эта модификация не бесплатна - она требует дополнительно O(n) памяти и одного полного прохода по массиву для сохранения исходных индексов.

Деградация по скорости в случае неудачного набора входных данных решается по двум разым направлениям: снижение вероятности возникновения худшего случая путём специального выбора опорного элемента и применение различных технических прёмов,
обеспечивающих устойчивую работу на неудачных входных данных. Для первого направления:
- Выбор среднего элемента. Устраняет деградацию для предварительно отсортированных данных, но оставляет возможность случайного появления или намеренного подбора "плохого" массива.
- Выбор медианы из трёх элементов: первого, среднего и последнего. Снижает вероятность возникновения худшего случая, по сравнению с просто выбором среднего элемента.
- Случайный выбор. Вероятность случайного возникновения худшего случая становится исчезающе малой, а намеренный подбор практически неосуществимым. 
Дополнительные накладные рассходы на данные модификации не велики.

Во избежании отказа программы из-за большой глубины рекурсии могут применяться следующие методы:
- При достижении нежелательной глубины рекурсии переходить на сортировку другими методами, не требующими рекурсию. Примером такого подхода является алгоритм Introsort. Он использует быструю сортировку и переключается на пирамидальную
сортировку (Heapsort), когда глубина рекурсии превысит некоторый заранее установленный уровень (например логарифм от числа сортируемых элементов). Т.к. после нескольких итераций быстрой сортировки массив с большой вероятностью окажется почти
отсортированным, то пирамидальная сортировка может довольно быстро закончить дело. Также пирамидальная сортировка хороша тем, что требует O(1) дополнительной памяти.
- Tail Call Optimization (TCO). Модификация алгоритма, устраняющая одну ветвь рекурсии: вместо того, чтобы после разделения массива вызывать рекурсивно процедуру разделения для обоих найденных подмассивов, рекурсивный вызов делается только для 
меньшего подмассива, а больший обрабатывается в цикле в пределах этого же вызова процедуры (хвостовая рекурсия). С точки зрения эффективности в среднем случае разницы практически нет: накладные расходы на дополнительный рекурсивный вызов и 
на организацию сравнения длин подмассивов и цикла - примерно одинакового порядка. Зато глубина рекурсии ни при каких обстоятельствах не превысит log_2 n, а в худшем случае вырожденного разделения она вообще будет не более 2 - вся обработка 
пройдёт в цикле первого уровня рекурсии. Применение этого метода не спасёт от катастрофического падаения производительности, но переполнения стека не будет.
- Разбивать массив не на две, а на три части.

Ещё одной оптимизацией является параллельная сортировка (PSRS) на основе быстрой. Пусть, исходный набор данных расположен на первом процессоре, с него начинается работа алгоритма. Затем исходный массив окажется разделённым на две части, 
меньшая из которых передаётся другому свободному процессору, большая остаётся на исходном для дальнейшей обработки. Далее обе части опять будут разделены и опять на двух исходных останутся большие части, а меньшие отправятся другим 
процессорам. В этом заключается ускорение алгоритма. При задействовании всех процессоров, все части параллельно будут сортироваться последовательным алгоритмом.


#####################
Итеративная быстрая сортировка (Без рекурсии)

int IterativeQuickSort(int* arr, size_t elements) {
    //https://translated.turbopages.org/proxy_u/en-ru.ru.8e4e096f-6849a79e-d4b70951-74722d776562/https/stackoverflow.com/questions/55008384/can-quicksort-be-implemented-in-c-without-stack-and-recursion
    size_t beg[48], end[48], L, R;
    int i = 0;

    beg[0] = 0;
    end[0] = elements;
    while (i >= 0) {
        L = beg[i];
        R = end[i];
        if (R - L > 1) {
            size_t M = L + ((R - L) >> 1);
            int piv = arr[M];
            arr[M] = arr[L];

            if (i == 48 - 1)
                return -1;
            R--;
            while (L < R) {
                while (arr[R] >= piv && L < R)
                    R--;
                if (L < R)
                    arr[L++] = arr[R];
                while (arr[L] <= piv && L < R)
                    L++;
                if (L < R)
                    arr[R--] = arr[L];
            }
            arr[L] = piv;
            M = L + 1;
            while (L > beg[i] && arr[L - 1] == piv)
                L--;
            while (M < end[i] && arr[M] == piv)
                M++;
            if (L - beg[i] > end[i] - M) {
                beg[i + 1] = M;
                end[i + 1] = end[i];
                end[i++] = L;
            }
            else {
                beg[i + 1] = beg[i];
                end[i + 1] = L;
                beg[i++] = M;
            }
        }
        else {
            i--;
        }
    }
    return 0;
}





#####################
#####################
Параллельная быстрая сортировка


#include <iostream>
#include <vector>
#include <thread>
#include <future>
#include <algorithm>

// Минимальный размер подмассива, при котором имеет смысл запускать параллельную сортировку
const size_t MIN_PARALLEL_SIZE = 10000;

// Максимальное количество потоков (равно количеству аппаратных ядер)
const unsigned int MAX_THREADS = std::thread::hardware_concurrency();

/// Рекурсивная функция быстрой сортировки с поддержкой параллельного выполнения
template <typename T>
void parallel_quicksort(std::vector<T>& data, int left, int right, unsigned depth = 0) {	// depth - глубина рекурсии, чтобы не создавать слишком много потоков
    // Базовый случай: если подмассив пустой или из одного элемента — ничего делать не нужно
    if (left >= right)
        return;

    // Выбор опорного элемента — середина подмассива
    T pivot = data[(left + right) / 2];

    // Указатели для разделения массива на две части
    int i = left, j = right;

    // Основной цикл разделения: размещаем элементы < pivot слева, > pivot — справа
    while (i <= j) {
        while (data[i] < pivot) ++i;      // ищем элемент больше или равный pivot
        while (data[j] > pivot) --j;      // ищем элемент меньше или равный pivot
        if (i <= j) {
            std::swap(data[i], data[j]); // меняем элементы местами
            ++i;
            --j;
        }
    }

    // Вычисляем размеры подмассивов после разделения
    auto left_size = j - left;
    auto right_size = right - i;

    // Решаем: стоит ли сортировать параллельно
    bool parallel_left = left_size > static_cast<int>(MIN_PARALLEL_SIZE) && depth < MAX_THREADS;
    bool parallel_right = right_size > static_cast<int>(MIN_PARALLEL_SIZE) && depth < MAX_THREADS;

    // Асинхронные задачи для левой и правой части
    std::future<void> left_future;
    std::future<void> right_future;

    // Сортируем левую часть
    if (parallel_left) {
        // Запускаем сортировку в отдельном потоке (через std::async)
        left_future = std::async(std::launch::async, [&]() {					// безопасный способ запускать задачи в параллели с автоматическим управлением потоком
            parallel_quicksort(data, left, j, depth + 1);
        });
    } else {
        // Сортируем обычным рекурсивным вызовом
        parallel_quicksort(data, left, j, depth);
    }

    // Аналогично для правой части
    if (parallel_right) {
        right_future = std::async(std::launch::async, [&]() {					// безопасный способ запускать задачи в параллели с автоматическим управлением потоком
            parallel_quicksort(data, i, right, depth + 1);
        });
    } else {
        parallel_quicksort(data, i, right, depth);
    }

    // Ждём завершения задач, если они были запущены в отдельных потоках
    if (parallel_left) left_future.wait();
    if (parallel_right) right_future.wait();
}

/// Обёртка, которую удобно вызывать снаружи
template <typename T>
void sort_parallel(std::vector<T>& data) {
    // Если массив маленький — сортируем обычным std::sort
    if (data.size() <= MIN_PARALLEL_SIZE) {
        std::sort(data.begin(), data.end());
    } else {
        // Иначе запускаем параллельную быструю сортировку
        parallel_quicksort(data, 0, static_cast<int>(data.size()) - 1);
    }
}


